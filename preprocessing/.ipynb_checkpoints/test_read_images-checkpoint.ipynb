{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    " \n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_utils import get_ETL8B_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W, H = 64, 64\n",
    "new_img = Image.new('1', (W, H))\n",
    "\n",
    "id_category = 0\n",
    "dataset = 1\n",
    "filename = '../ETLC/ETL8B/ETL8B2C'+str(dataset)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "with open(filename, 'r') as f:\n",
    "    f.seek((id_category * 160 + 1) * 512)\n",
    "    for i in range(160):\n",
    "        try:\n",
    "            r = read_record_ETL8B2(f)\n",
    "            new_img.paste(r[-1], (0,0))    \n",
    "            iI = Image.eval(new_img, lambda x: not x)\n",
    "\n",
    "            X.append(np.asarray(new_img.getdata()).reshape(W,H))\n",
    "            Y.append(r[1])\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img.thumbnail((32,32), Image.ANTIALIAS)\n",
    "new_img\n",
    "np.asarray(new_img.getdata()).reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1736a3150>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD+CAYAAAAalrhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182ce9450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1+51200 records\n",
    "# 320 categories\n",
    "# 160 writers per category\n",
    "# X_small, Y_small = get_ETL8B_data(1, 10, 20, resize=(32,32))\n",
    "X_small, Y_small = get_ETL8B_data(1, range(0,75), 1)\n",
    "imshow(X_small[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, cross_validation\n",
    "import skflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "# Hiragana data set with subset of writers\n",
    "characters, labels = get_ETL8B_data(1, range(0,75), 20, vectorize=True)\n",
    "\n",
    "# rename labels from 0 to n_labels-1\n",
    "unique_labels = list(set(labels))\n",
    "labels_dict = {unique_labels[i]:i for i in range(len(unique_labels))}\n",
    "new_labels = np.array([labels_dict[l] for l in labels], dtype=np.int32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(characters,\n",
    "                                                                     new_labels,\n",
    "                                                                     test_size=0.3,\n",
    "                                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.int32'> <type 'numpy.int32'>\n",
      "(1050, 4096) (1050,)\n"
     ]
    }
   ],
   "source": [
    "# confirm data type and shapes\n",
    "print type(X_train[0,0]), type(y_train[0])\n",
    "print X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(tensor_in):\n",
    "    return tf.nn.max_pool(tensor_in,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def conv_model(X, y):\n",
    "    # reshape X to 4d tensor with 2nd and 3rd dimensions being image width and height\n",
    "    # final dimension being the number of color channels\n",
    "    X = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    # first conv layer will compute 32 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer1'):\n",
    "        h_conv1 = skflow.ops.conv2d(X, n_filters=32, filter_shape=[5, 5], \n",
    "                                    bias=True, activation=tf.nn.relu)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "    # second conv layer will compute 64 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer2'):\n",
    "        h_conv2 = skflow.ops.conv2d(h_pool1, n_filters=64, filter_shape=[5, 5], \n",
    "                                    bias=True, activation=tf.nn.relu)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        # reshape tensor into a batch of vectors\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "    # densely connected layer with 1024 neurons\n",
    "    h_fc1 = skflow.ops.dnn(h_pool2_flat, [1024], activation=tf.nn.relu, keep_prob=0.5)\n",
    "    return skflow.models.logistic_regression(h_fc1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 90.40005\n",
      "Step #51, epoch #1, avg. loss: 17.13533\n",
      "Step #101, epoch #3, avg. loss: 3.78853\n",
      "Step #151, epoch #4, avg. loss: 2.28438\n",
      "Step #201, epoch #6, avg. loss: 1.81317\n",
      "Step #251, epoch #7, avg. loss: 1.44622\n",
      "Step #301, epoch #9, avg. loss: 1.31722\n",
      "Step #351, epoch #10, avg. loss: 0.99314\n",
      "Step #401, epoch #12, avg. loss: 1.14714\n",
      "Step #451, epoch #13, avg. loss: 0.96209\n",
      "Accuracy: 0.914286\n"
     ]
    }
   ],
   "source": [
    "# Start with a DNN and try to overfit\n",
    "n_classes = len(set(labels))\n",
    "classifier = skflow.TensorFlowDNNClassifier(hidden_units=[500,500,500],\n",
    "                                            n_classes=n_classes,\n",
    "                                            steps=500)\n",
    "\n",
    "# Fit and predict.\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_train)\n",
    "score = metrics.accuracy_score(y_train, y_pred)\n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input has 409600 values, which isn't divisible by 784\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_0, Reshape/shape)]]\nCaused by op u'Reshape', defined at:\n  File \"/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/ctsai89/Library/Python/2.7/lib/python/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-359-8844ff6f315f>\", line 9, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/usr/local/lib/python2.7/site-packages/skflow/estimators/base.py\", line 188, in fit\n    self._setup_training()\n  File \"/usr/local/lib/python2.7/site-packages/skflow/estimators/base.py\", line 127, in _setup_training\n    self._inp, self._out)\n  File \"<ipython-input-356-330165735489>\", line 10, in conv_model\n    X = tf.reshape(X, [-1, 28, 28, 1])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 554, in reshape\n    name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-8844ff6f315f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                         learning_rate=0.001)\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fit and predict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/skflow/estimators/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, logdir)\u001b[0m\n\u001b[1;32m    212\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_early_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                             feed_params_fn=self._data_feeder.get_feed_params)\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/skflow/trainer.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, feed_dict_fn, steps, summary_writer, summaries, print_steps, verbose, early_stopping_rounds, feed_params_fn)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 global_step, loss, summ, _ = sess.run(\n\u001b[1;32m    146\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                     feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 global_step, loss, _ = sess.run(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         raise errors._make_specific_exception(node_def, op, e.error_message,\n\u001b[0;32m--> 419\u001b[0;31m                                               e.code)\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input has 409600 values, which isn't divisible by 784\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_0, Reshape/shape)]]\nCaused by op u'Reshape', defined at:\n  File \"/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/ctsai89/Library/Python/2.7/lib/python/site-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-359-8844ff6f315f>\", line 9, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/usr/local/lib/python2.7/site-packages/skflow/estimators/base.py\", line 188, in fit\n    self._setup_training()\n  File \"/usr/local/lib/python2.7/site-packages/skflow/estimators/base.py\", line 127, in _setup_training\n    self._inp, self._out)\n  File \"<ipython-input-356-330165735489>\", line 10, in conv_model\n    X = tf.reshape(X, [-1, 28, 28, 1])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 554, in reshape\n    name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Training and predicting\n",
    "n_classes = len(set(labels))\n",
    "classifier = skflow.TensorFlowEstimator(model_fn=conv_model,\n",
    "                                        n_classes=n_classes,\n",
    "                                        batch_size=100,\n",
    "                                        steps=200,\n",
    "                                        learning_rate=0.001)\n",
    "# Fit and predict.\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
